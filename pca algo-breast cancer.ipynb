{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as la\n",
    "import statistics\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame( pd.read_csv(\"Breast_cancer.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_1ean</th>\n",
       "      <th>texture_1ean</th>\n",
       "      <th>peri1eter_1ean</th>\n",
       "      <th>area_1ean</th>\n",
       "      <th>s1oothness_1ean</th>\n",
       "      <th>co1pactness_1ean</th>\n",
       "      <th>concavity_1ean</th>\n",
       "      <th>concave points_1ean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>peri1eter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>s1oothness_worst</th>\n",
       "      <th>co1pactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>sy11etry_worst</th>\n",
       "      <th>fractal_di1ension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>926424</td>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>926682</td>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>926954</td>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>927241</td>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>92751</td>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  diagnosis  radius_1ean  texture_1ean  peri1eter_1ean  \\\n",
       "0      842302          1        17.99         10.38          122.80   \n",
       "1      842517          1        20.57         17.77          132.90   \n",
       "2    84300903          1        19.69         21.25          130.00   \n",
       "3    84348301          1        11.42         20.38           77.58   \n",
       "4    84358402          1        20.29         14.34          135.10   \n",
       "..        ...        ...          ...           ...             ...   \n",
       "564    926424          1        21.56         22.39          142.00   \n",
       "565    926682          1        20.13         28.25          131.20   \n",
       "566    926954          1        16.60         28.08          108.30   \n",
       "567    927241          1        20.60         29.33          140.10   \n",
       "568     92751          0         7.76         24.54           47.92   \n",
       "\n",
       "     area_1ean  s1oothness_1ean  co1pactness_1ean  concavity_1ean  \\\n",
       "0       1001.0          0.11840           0.27760         0.30010   \n",
       "1       1326.0          0.08474           0.07864         0.08690   \n",
       "2       1203.0          0.10960           0.15990         0.19740   \n",
       "3        386.1          0.14250           0.28390         0.24140   \n",
       "4       1297.0          0.10030           0.13280         0.19800   \n",
       "..         ...              ...               ...             ...   \n",
       "564     1479.0          0.11100           0.11590         0.24390   \n",
       "565     1261.0          0.09780           0.10340         0.14400   \n",
       "566      858.1          0.08455           0.10230         0.09251   \n",
       "567     1265.0          0.11780           0.27700         0.35140   \n",
       "568      181.0          0.05263           0.04362         0.00000   \n",
       "\n",
       "     concave points_1ean  ...  radius_worst  texture_worst  peri1eter_worst  \\\n",
       "0                0.14710  ...        25.380          17.33           184.60   \n",
       "1                0.07017  ...        24.990          23.41           158.80   \n",
       "2                0.12790  ...        23.570          25.53           152.50   \n",
       "3                0.10520  ...        14.910          26.50            98.87   \n",
       "4                0.10430  ...        22.540          16.67           152.20   \n",
       "..                   ...  ...           ...            ...              ...   \n",
       "564              0.13890  ...        25.450          26.40           166.10   \n",
       "565              0.09791  ...        23.690          38.25           155.00   \n",
       "566              0.05302  ...        18.980          34.12           126.70   \n",
       "567              0.15200  ...        25.740          39.42           184.60   \n",
       "568              0.00000  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  s1oothness_worst  co1pactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  sy11etry_worst  fractal_di1ension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 2:32].values \n",
    "y = dataset.iloc[:, 1].values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1       2       3        4        5        6        7       8   \\\n",
       "0    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n",
       "1    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
       "2    19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
       "3    11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
       "4    20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
       "..     ...    ...     ...     ...      ...      ...      ...      ...     ...   \n",
       "564  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890  0.1726   \n",
       "565  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791  0.1752   \n",
       "566  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302  0.1590   \n",
       "567  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200  0.2397   \n",
       "568   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000  0.1587   \n",
       "\n",
       "          9   ...      20     21      22      23       24       25      26  \\\n",
       "0    0.07871  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119   \n",
       "1    0.05667  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n",
       "2    0.05999  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n",
       "3    0.09744  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n",
       "4    0.05883  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n",
       "..       ...  ...     ...    ...     ...     ...      ...      ...     ...   \n",
       "564  0.05623  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
       "565  0.05533  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
       "566  0.05648  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
       "567  0.07016  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
       "568  0.05884  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
       "\n",
       "         27      28       29  \n",
       "0    0.2654  0.4601  0.11890  \n",
       "1    0.1860  0.2750  0.08902  \n",
       "2    0.2430  0.3613  0.08758  \n",
       "3    0.2575  0.6638  0.17300  \n",
       "4    0.1625  0.2364  0.07678  \n",
       "..      ...     ...      ...  \n",
       "564  0.2216  0.2060  0.07115  \n",
       "565  0.1628  0.2572  0.06637  \n",
       "566  0.1418  0.2218  0.07820  \n",
       "567  0.2650  0.4087  0.12400  \n",
       "568  0.0000  0.2871  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHI SQUARE TEST + KENDALL CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Chi2 Stat===\n",
      "26466.265203463237\n",
      "\n",
      "\n",
      "===Degrees of Freedom===\n",
      "16472\n",
      "\n",
      "\n",
      "===P-Value===\n",
      "0.0\n",
      "\n",
      "\n",
      "===Contingency Table===\n",
      "[[2.71340894e+01 3.70493550e+01 1.76643622e+02 ... 2.20122552e-01\n",
      "  5.57144046e-01 1.61233544e-01]\n",
      " [2.84636769e+01 3.88647968e+01 1.85299270e+02 ... 2.30908696e-01\n",
      "  5.84444456e-01 1.69134089e-01]\n",
      " [2.57737556e+01 3.51919317e+01 1.67787813e+02 ... 2.09086981e-01\n",
      "  5.29212323e-01 1.53150301e-01]\n",
      " ...\n",
      " [1.80346900e+01 2.46248776e+01 1.17406297e+02 ... 1.46304596e-01\n",
      "  3.70306149e-01 1.07163979e-01]\n",
      " [2.75760609e+01 3.76528306e+01 1.79520868e+02 ... 2.23708001e-01\n",
      "  5.66219045e-01 1.63859784e-01]\n",
      " [4.96990662e+00 6.78599647e+00 3.23542202e+01 ... 4.03178640e-02\n",
      "  1.02047054e-01 2.95316952e-02]]\n"
     ]
    }
   ],
   "source": [
    "chi2_stat, p_val, dof, ex = stats.chi2_contingency(X)\n",
    "print(\"===Chi2 Stat===\")\n",
    "print(chi2_stat)\n",
    "print(\"\\n\")\n",
    "print(\"===Degrees of Freedom===\")\n",
    "print(dof)\n",
    "print(\"\\n\")\n",
    "print(\"===P-Value===\")\n",
    "print(p_val)\n",
    "print(\"\\n\")\n",
    "print(\"===Contingency Table===\")\n",
    "print(ex)\n",
    "mean = ex.mean(axis=0)\n",
    "X= ex -mean #(to normalize it)\n",
    "# X=ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.DataFrame(X).corr(method='kendall')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenValues, eigenVectors = np.linalg.eig(corr)\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = eigenVectors.T.dot(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 312.10273858  344.00666377  279.46104462 ...   93.75941118\n",
      "   322.70800291 -219.73471454]\n",
      " [  54.37350737   59.93170375   48.68677935 ...   16.33445467\n",
      "    56.22112146  -38.28145557]\n",
      " [-347.99666942 -383.5697623  -311.60095936 ... -104.54237911\n",
      "  -359.82161104  245.0056964 ]\n",
      " ...\n",
      " [  39.96675619   44.05225831   35.78677805 ...   12.00649358\n",
      "    41.32482827  -28.13843865]\n",
      " [-102.36962625 -112.83410636  -91.66315816 ...  -30.75306524\n",
      "  -105.84815051   72.07293568]\n",
      " [  37.89426675   41.7679138    33.93104277 ...   11.38389286\n",
      "    39.18191555  -26.67931055]]\n"
     ]
    }
   ],
   "source": [
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = P.T[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 312.10273858,   54.37350737],\n",
       "       [ 344.00666377,   59.93170375],\n",
       "       [ 279.46104462,   48.68677935],\n",
       "       ...,\n",
       "       [  93.75941118,   16.33445467],\n",
       "       [ 322.70800291,   56.22112146],\n",
       "       [-219.73471454,  -38.28145557]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance score: 0.916083916083916\n",
      "[[86  4]\n",
      " [ 8 45]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishthagoel/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset1, y, test_size = 0.25, random_state = 0) \n",
    "reg = linear_model.LogisticRegression()\n",
    "reg.fit(X_train, y_train) \n",
    "# variance score: 1 means perfect prediction \n",
    "print('Variance score: {}'.format(reg.score(X_test, y_test)))\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHI SQUARE TEST + PEARSON CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 2:32].values \n",
    "y = dataset.iloc[:, 1].values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Chi2 Stat===\n",
      "26466.265203463237\n",
      "\n",
      "\n",
      "===Degrees of Freedom===\n",
      "16472\n",
      "\n",
      "\n",
      "===P-Value===\n",
      "0.0\n",
      "\n",
      "\n",
      "===Contingency Table===\n",
      "[[2.71340894e+01 3.70493550e+01 1.76643622e+02 ... 2.20122552e-01\n",
      "  5.57144046e-01 1.61233544e-01]\n",
      " [2.84636769e+01 3.88647968e+01 1.85299270e+02 ... 2.30908696e-01\n",
      "  5.84444456e-01 1.69134089e-01]\n",
      " [2.57737556e+01 3.51919317e+01 1.67787813e+02 ... 2.09086981e-01\n",
      "  5.29212323e-01 1.53150301e-01]\n",
      " ...\n",
      " [1.80346900e+01 2.46248776e+01 1.17406297e+02 ... 1.46304596e-01\n",
      "  3.70306149e-01 1.07163979e-01]\n",
      " [2.75760609e+01 3.76528306e+01 1.79520868e+02 ... 2.23708001e-01\n",
      "  5.66219045e-01 1.63859784e-01]\n",
      " [4.96990662e+00 6.78599647e+00 3.23542202e+01 ... 4.03178640e-02\n",
      "  1.02047054e-01 2.95316952e-02]]\n"
     ]
    }
   ],
   "source": [
    "chi2_stat, p_val, dof, ex = stats.chi2_contingency(X)\n",
    "print(\"===Chi2 Stat===\")\n",
    "print(chi2_stat)\n",
    "print(\"\\n\")\n",
    "print(\"===Degrees of Freedom===\")\n",
    "print(dof)\n",
    "print(\"\\n\")\n",
    "print(\"===P-Value===\")\n",
    "print(p_val)\n",
    "print(\"\\n\")\n",
    "print(\"===Contingency Table===\")\n",
    "print(ex)\n",
    "mean = ex.mean(axis=0)\n",
    "X= ex -mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.DataFrame(X).corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenValues, eigenVectors = np.linalg.eig(corr)\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = eigenVectors.T.dot(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = P.T[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = dataset2.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance score: 0.916083916083916\n",
      "[[86  4]\n",
      " [ 8 45]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishthagoel/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset2, y, test_size = 0.25, random_state = 0) \n",
    "reg = linear_model.LogisticRegression()\n",
    "reg.fit(X_train, y_train) \n",
    "# variance score: 1 means perfect prediction \n",
    "print('Variance score: {}'.format(reg.score(X_test, y_test)))\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHI SQUARE + SPEARMAN CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 2:32].values \n",
    "y = dataset.iloc[:, 1].values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Chi2 Stat===\n",
      "26466.265203463237\n",
      "\n",
      "\n",
      "===Degrees of Freedom===\n",
      "16472\n",
      "\n",
      "\n",
      "===P-Value===\n",
      "0.0\n",
      "\n",
      "\n",
      "===Contingency Table===\n",
      "[[2.71340894e+01 3.70493550e+01 1.76643622e+02 ... 2.20122552e-01\n",
      "  5.57144046e-01 1.61233544e-01]\n",
      " [2.84636769e+01 3.88647968e+01 1.85299270e+02 ... 2.30908696e-01\n",
      "  5.84444456e-01 1.69134089e-01]\n",
      " [2.57737556e+01 3.51919317e+01 1.67787813e+02 ... 2.09086981e-01\n",
      "  5.29212323e-01 1.53150301e-01]\n",
      " ...\n",
      " [1.80346900e+01 2.46248776e+01 1.17406297e+02 ... 1.46304596e-01\n",
      "  3.70306149e-01 1.07163979e-01]\n",
      " [2.75760609e+01 3.76528306e+01 1.79520868e+02 ... 2.23708001e-01\n",
      "  5.66219045e-01 1.63859784e-01]\n",
      " [4.96990662e+00 6.78599647e+00 3.23542202e+01 ... 4.03178640e-02\n",
      "  1.02047054e-01 2.95316952e-02]]\n"
     ]
    }
   ],
   "source": [
    "chi2_stat, p_val, dof, ex = stats.chi2_contingency(X)\n",
    "print(\"===Chi2 Stat===\")\n",
    "print(chi2_stat)\n",
    "print(\"\\n\")\n",
    "print(\"===Degrees of Freedom===\")\n",
    "print(dof)\n",
    "print(\"\\n\")\n",
    "print(\"===P-Value===\")\n",
    "print(p_val)\n",
    "print(\"\\n\")\n",
    "print(\"===Contingency Table===\")\n",
    "print(ex)\n",
    "mean = ex.mean(axis=0)\n",
    "X= ex -mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.DataFrame(X).corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenValues, eigenVectors = np.linalg.eig(corr)\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = eigenVectors.T.dot(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = P.T[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 312.10273858,   53.14629781],\n",
       "       [ 344.00666377,   58.57904575],\n",
       "       [ 279.46104462,   47.5879192 ],\n",
       "       ...,\n",
       "       [  93.75941118,   15.96578618],\n",
       "       [ 322.70800291,   54.95221127],\n",
       "       [-219.73471454,  -37.41744347]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance score: 0.916083916083916\n",
      "[[86  4]\n",
      " [ 8 45]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishthagoel/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset3, y, test_size = 0.25, random_state = 0) \n",
    "reg = linear_model.LogisticRegression()\n",
    "reg.fit(X_train, y_train) \n",
    "# variance score: 1 means perfect prediction \n",
    "print('Variance score: {}'.format(reg.score(X_test, y_test)))\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLY PCA (using covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 2:32].values \n",
    "y = dataset.iloc[:, 1].values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= X -mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = np.cov(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenValues, eigenVectors = np.linalg.eig(ret)\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = eigenVectors.T.dot(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4 = P.T[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1160.1425737 , -293.91754364],\n",
       "       [1269.12244319,   15.63018184],\n",
       "       [ 995.79388896,   39.15674324],\n",
       "       ...,\n",
       "       [ 314.50175618,   47.55352518],\n",
       "       [1124.85811531,   34.12922497],\n",
       "       [-771.52762188,  -88.64310636]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance score: 0.9440559440559441\n",
      "[[87  3]\n",
      " [ 5 48]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishthagoel/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset4, y, test_size = 0.25, random_state = 0) \n",
    "reg = linear_model.LogisticRegression()\n",
    "reg.fit(X_train, y_train) \n",
    "# variance score: 1 means perfect prediction \n",
    "print('Variance score: {}'.format(reg.score(X_test, y_test)))\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITH PCA DIRECT FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 2:32].values \n",
    "y = dataset.iloc[:, 1].values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X.mean(axis=0)\n",
    "X= X -mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(2)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.08623202e-03  2.19657026e-03  3.50763298e-02  5.16826469e-01\n",
      "   4.23694535e-06  4.05260047e-05  8.19399539e-05  4.77807775e-05\n",
      "   7.07804332e-06 -2.62155251e-06  3.13742507e-04 -6.50984008e-05\n",
      "   2.23634150e-03  5.57271669e-02 -8.05646029e-07  5.51918197e-06\n",
      "   8.87094462e-06  3.27915009e-06 -1.24101836e-06 -8.54530832e-08\n",
      "   7.15473257e-03  3.06736622e-03  4.94576447e-02  8.52063392e-01\n",
      "   6.42005481e-06  1.01275937e-04  1.68928625e-04  7.36658178e-05\n",
      "   1.78986262e-05  1.61356159e-06]\n",
      " [ 9.28705650e-03 -2.88160658e-03  6.27480827e-02  8.51823720e-01\n",
      "  -1.48194356e-05 -2.68862249e-06  7.51419574e-05  4.63501038e-05\n",
      "  -2.52430431e-05 -1.61197148e-05 -5.38692831e-05  3.48370414e-04\n",
      "   8.19640791e-04  7.51112451e-03  1.49438131e-06  1.27357957e-05\n",
      "   2.86921009e-05  9.36007477e-06  1.22647432e-05  2.89683790e-07\n",
      "  -5.68673345e-04 -1.32152605e-02 -1.85961117e-04 -5.19742358e-01\n",
      "  -7.68565692e-05 -2.56104144e-04 -1.75471479e-04 -3.05051743e-05\n",
      "  -1.57042845e-04 -5.53071662e-05]]\n",
      "[443782.6051466    7310.10006165]\n"
     ]
    }
   ],
   "source": [
    "print(pca.components_)\n",
    "print(pca.explained_variance_)\n",
    "B = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance score: 0.9440559440559441\n",
      "[[87  3]\n",
      " [ 5 48]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishthagoel/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(B, y, test_size = 0.25, random_state = 0) \n",
    "reg = linear_model.LogisticRegression()\n",
    "reg.fit(X_train, y_train) \n",
    "# variance score: 1 means perfect prediction \n",
    "print('Variance score: {}'.format(reg.score(X_test, y_test)))\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVARIANCE AND CHI SQUARE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 2:32].values \n",
    "y = dataset.iloc[:, 1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Chi2 Stat===\n",
      "26466.265203463237\n",
      "\n",
      "\n",
      "===Degrees of Freedom===\n",
      "16472\n",
      "\n",
      "\n",
      "===P-Value===\n",
      "0.0\n",
      "\n",
      "\n",
      "===Contingency Table===\n",
      "[[2.71340894e+01 3.70493550e+01 1.76643622e+02 ... 2.20122552e-01\n",
      "  5.57144046e-01 1.61233544e-01]\n",
      " [2.84636769e+01 3.88647968e+01 1.85299270e+02 ... 2.30908696e-01\n",
      "  5.84444456e-01 1.69134089e-01]\n",
      " [2.57737556e+01 3.51919317e+01 1.67787813e+02 ... 2.09086981e-01\n",
      "  5.29212323e-01 1.53150301e-01]\n",
      " ...\n",
      " [1.80346900e+01 2.46248776e+01 1.17406297e+02 ... 1.46304596e-01\n",
      "  3.70306149e-01 1.07163979e-01]\n",
      " [2.75760609e+01 3.76528306e+01 1.79520868e+02 ... 2.23708001e-01\n",
      "  5.66219045e-01 1.63859784e-01]\n",
      " [4.96990662e+00 6.78599647e+00 3.23542202e+01 ... 4.03178640e-02\n",
      "  1.02047054e-01 2.95316952e-02]]\n"
     ]
    }
   ],
   "source": [
    "chi2_stat, p_val, dof, ex = stats.chi2_contingency(X)\n",
    "print(\"===Chi2 Stat===\")\n",
    "print(chi2_stat)\n",
    "print(\"\\n\")\n",
    "print(\"===Degrees of Freedom===\")\n",
    "print(dof)\n",
    "print(\"\\n\")\n",
    "print(\"===P-Value===\")\n",
    "print(p_val)\n",
    "print(\"\\n\")\n",
    "print(\"===Contingency Table===\")\n",
    "print(ex)\n",
    "mean = ex.mean(axis=0)\n",
    "X= ex -mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = np.cov(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenValues, eigenVectors = np.linalg.eig(ret)\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = eigenVectors.T.dot(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.02001132e+03+0.j  1.43628982e-13+0.j]\n",
      " [-1.12427943e+03+0.j  2.23172640e-13+0.j]\n",
      " [-9.13332032e+02+0.j  2.69413718e-13+0.j]\n",
      " ...\n",
      " [-3.06423651e+02+0.j  1.33014333e-14+0.j]\n",
      " [-1.05467135e+03+0.j  5.13628694e-14+0.j]\n",
      " [ 7.18134986e+02+0.j -3.33577170e-13+0.j]]\n"
     ]
    }
   ],
   "source": [
    "dataset8 = P.T[:,:2]\n",
    "print(dataset8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset8 = dataset8.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance score: 0.916083916083916\n",
      "[[86  4]\n",
      " [ 8 45]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishthagoel/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset8, y, test_size = 0.25, random_state = 0) \n",
    "reg = linear_model.LogisticRegression()\n",
    "reg.fit(X_train, y_train) \n",
    "# variance score: 1 means perfect prediction \n",
    "print('Variance score: {}'.format(reg.score(X_test, y_test)))\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA WITH CORRELATION AS KENDALL (no chi square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 2:32].values \n",
    "y = dataset.iloc[:, 1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X.mean(axis=0)\n",
    "X= X -mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.DataFrame(X).corr(method='kendall')\n",
    "#print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenValues, eigenVectors = np.linalg.eig(corr)\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = eigenVectors.T.dot(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 400.13949649  409.42453626]\n",
      " [ 438.5173402   470.68635914]\n",
      " [ 354.76797439  376.37052344]\n",
      " ...\n",
      " [ 116.94653915  124.41019967]\n",
      " [ 407.43842153  430.16585487]\n",
      " [-280.65466976 -302.42781283]]\n"
     ]
    }
   ],
   "source": [
    "dataset5 = P.T[:,:2]\n",
    "print(dataset5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance score: 0.9300699300699301\n",
      "[[83  7]\n",
      " [ 3 50]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishthagoel/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset5, y, test_size = 0.25, random_state = 0) \n",
    "reg = linear_model.LogisticRegression()\n",
    "reg.fit(X_train, y_train) \n",
    "# variance score: 1 means perfect prediction \n",
    "print('Variance score: {}'.format(reg.score(X_test, y_test)))\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA WITH CORRELATION AS PEARSON (no chi square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 2:32].values \n",
    "y = dataset.iloc[:, 1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X.mean(axis=0)\n",
    "X= X -mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.DataFrame(X).corr(method='pearson')\n",
    "#print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenValues, eigenVectors = np.linalg.eig(corr)\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = eigenVectors.T.dot(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 383.60866056 -371.40157776]\n",
      " [ 421.62029129 -418.58821576]\n",
      " [ 341.35578716 -336.93933293]\n",
      " ...\n",
      " [ 112.73085654 -111.15701026]\n",
      " [ 392.10917675 -384.88780784]\n",
      " [-270.23641711  268.47067306]]\n"
     ]
    }
   ],
   "source": [
    "dataset6 = P.T[:,:2]\n",
    "print(dataset6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance score: 0.9370629370629371\n",
      "[[83  7]\n",
      " [ 2 51]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishthagoel/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset6, y, test_size = 0.25, random_state = 0) \n",
    "reg = linear_model.LogisticRegression()\n",
    "reg.fit(X_train, y_train) \n",
    "# variance score: 1 means perfect prediction \n",
    "print('Variance score: {}'.format(reg.score(X_test, y_test)))\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA WITH CORRELATION AS SPEARMAN (no chi square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 2:32].values \n",
    "y = dataset.iloc[:, 1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X.mean(axis=0)\n",
    "X= X -mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.DataFrame(X).corr(method='spearman')\n",
    "#print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenValues, eigenVectors = np.linalg.eig(corr)\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = eigenVectors.T.dot(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 369.67298024  394.55669762]\n",
      " [ 403.12166842  451.83774546]\n",
      " [ 326.75442691  362.03173371]\n",
      " ...\n",
      " [ 107.80581088  119.89379707]\n",
      " [ 375.49341426  414.05060752]\n",
      " [-257.85407273 -290.13799769]]\n"
     ]
    }
   ],
   "source": [
    "dataset7 = P.T[:,:2]\n",
    "print(dataset7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance score: 0.9300699300699301\n",
      "[[83  7]\n",
      " [ 3 50]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishthagoel/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset7, y, test_size = 0.25, random_state = 0) \n",
    "reg = linear_model.LogisticRegression()\n",
    "reg.fit(X_train, y_train) \n",
    "# variance score: 1 means perfect prediction \n",
    "print('Variance score: {}'.format(reg.score(X_test, y_test)))\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame( pd.read_csv(\"Breast_cancer.csv\"))\n",
    "X = dataset.iloc[:, 2:32].values \n",
    "y = dataset.iloc[:, 1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishthagoel/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 2 - 1) = 1 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/Users/nishthagoel/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lda=LDA(n_components=2)\n",
    "L=lda.fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance score: 0.972027972027972\n",
      "[[89  1]\n",
      " [ 3 50]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishthagoel/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(L, y, test_size = 0.25, random_state = 0) \n",
    "reg = linear_model.LogisticRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "# variance score: 1 means perfect prediction \n",
    "print('Variance score: {}'.format(reg.score(X_test, y_test)))\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA WITH CHI SQUARE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame( pd.read_csv(\"Breast_cancer.csv\"))\n",
    "X = dataset.iloc[:, 2:32].values \n",
    "y = dataset.iloc[:, 1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Chi2 Stat===\n",
      "26466.265203463237\n",
      "\n",
      "\n",
      "===Degrees of Freedom===\n",
      "16472\n",
      "\n",
      "\n",
      "===P-Value===\n",
      "0.0\n",
      "\n",
      "\n",
      "===Contingency Table===\n",
      "[[2.71340894e+01 3.70493550e+01 1.76643622e+02 ... 2.20122552e-01\n",
      "  5.57144046e-01 1.61233544e-01]\n",
      " [2.84636769e+01 3.88647968e+01 1.85299270e+02 ... 2.30908696e-01\n",
      "  5.84444456e-01 1.69134089e-01]\n",
      " [2.57737556e+01 3.51919317e+01 1.67787813e+02 ... 2.09086981e-01\n",
      "  5.29212323e-01 1.53150301e-01]\n",
      " ...\n",
      " [1.80346900e+01 2.46248776e+01 1.17406297e+02 ... 1.46304596e-01\n",
      "  3.70306149e-01 1.07163979e-01]\n",
      " [2.75760609e+01 3.76528306e+01 1.79520868e+02 ... 2.23708001e-01\n",
      "  5.66219045e-01 1.63859784e-01]\n",
      " [4.96990662e+00 6.78599647e+00 3.23542202e+01 ... 4.03178640e-02\n",
      "  1.02047054e-01 2.95316952e-02]]\n"
     ]
    }
   ],
   "source": [
    "chi2_stat, p_val, dof, ex = stats.chi2_contingency(X)\n",
    "print(\"===Chi2 Stat===\")\n",
    "print(chi2_stat)\n",
    "print(\"\\n\")\n",
    "print(\"===Degrees of Freedom===\")\n",
    "print(dof)\n",
    "print(\"\\n\")\n",
    "print(\"===P-Value===\")\n",
    "print(p_val)\n",
    "print(\"\\n\")\n",
    "print(\"===Contingency Table===\")\n",
    "print(ex)\n",
    "mean = ex.mean(axis=0)\n",
    "X= ex -mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishthagoel/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 2 - 1) = 1 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/Users/nishthagoel/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n",
      "/Users/nishthagoel/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "lda=LDA(n_components=2)\n",
    "L1=lda.fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance score: 0.916083916083916\n",
      "[[86  4]\n",
      " [ 8 45]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishthagoel/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(L1, y, test_size = 0.25, random_state = 0) \n",
    "reg = linear_model.LogisticRegression()\n",
    "reg.fit(X_train, y_train) \n",
    "# variance score: 1 means perfect prediction \n",
    "print('Variance score: {}'.format(reg.score(X_test, y_test)))\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NO PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance score: 0.958041958041958\n",
      "[[85  5]\n",
      " [ 1 52]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishthagoel/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import datasets, linear_model, metrics \n",
    "from sklearn.model_selection import train_test_split \n",
    "X = dataset.iloc[:, 2:32].values \n",
    "y = dataset.iloc[:, 1].values \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0) \n",
    "reg = linear_model.LogisticRegression()\n",
    "reg.fit(X_train, y_train) \n",
    "# variance score: 1 means perfect prediction \n",
    "print('Variance score: {}'.format(reg.score(X_test, y_test))) \n",
    "y_pred = reg.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT : BARGRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "left = [ 1,2,3,4,5,6,7,8] \n",
    "plt.rcParams.update({'font.size': 20})\n",
    " \n",
    "# heights of bars \n",
    "height = [94.40559440559441, \n",
    "          93.00699300699301, \n",
    "          93.00699300699301,\n",
    "          93.70629370629371,\n",
    "          91.6083916083916,\n",
    "          91.6083916083916,\n",
    "          91.6083916083916,\n",
    "          91.6083916083916\n",
    "] \n",
    "  \n",
    "# labels for bars \n",
    "tick_label = ['PCA', \n",
    "              'Kendall \\n Correlation Matrix', \n",
    "              'Spearman \\n Correlation Matrix',\n",
    "              'Pearson \\n Correlation Matrix',\n",
    "              'Contigency table + \\n Kendall Correlation Matrix',\n",
    "              'Contigency table + \\n Spearman Correlation Matrix', \n",
    "              'Contigency table + \\n Pearson Correlation Matrix',\n",
    "              'Contigency table + \\n Covariance Matrix'] \n",
    "\n",
    "low = min(height)\n",
    "high = max(height)\n",
    "plt.figure(figsize=(25,10))\n",
    "plt.ylim([math.ceil(low-0.5*(high-low)), math.ceil(high+0.2*(high-low))])\n",
    "#plt.xlim(10, 10)\n",
    "plt.yticks(fontsize=18)\n",
    "#plt.subplots(figsize=(30,15))\n",
    "plt.bar(left, height, tick_label = tick_label, \n",
    "        width = 0.6, color = ['red', 'midnightblue','royalblue','blue','darkseagreen','yellowgreen','olivedrab',\n",
    "                              'green']) \n",
    "\n",
    "# naming the x-axis \n",
    "plt.xlabel('\\nCategories') \n",
    "# naming the y-axis \n",
    "plt.ylabel('Accuracy\\n') \n",
    "# plot title \n",
    "plt.title('Bar chart plot') \n",
    "plt.tick_params(axis='x', which='major', labelsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# function to show the plot \n",
    "plt.show() \n",
    "#plt.savefig(\"/Users/nishthagoel/Desktop/preprocessing/plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
